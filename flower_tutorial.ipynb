{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz71fPGrpRiQ"
      },
      "source": [
        "# Intro to Federated Learning with Flower and scikit-learn\n",
        "\n",
        "Alex Kyllo 2022-10-29\n",
        "\n",
        "In this notebook, we'll build a simulated federated learning system using Flower\n",
        "and scikit-learn.\n",
        "\n",
        "In a production FL environment, you would have a central server communicating\n",
        "with many clients on different machines (like smartphones) over the network, but\n",
        "Flower provides a simulation framework so that you can run a whole FL environment\n",
        "locally, even in a Jupyter notebook like this.\n",
        "\n",
        "Let's get started! 沍ｻ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBu1HRRY6bwX"
      },
      "source": [
        "## Part 0: Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4KiTMTpiort"
      },
      "source": [
        "### Installing dependencies\n",
        "\n",
        "First, let's install Python packages we need to run the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eTrCL2FmC5U5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flwr[simulation] in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (1.0.0)\n",
            "Requirement already satisfied: scikit-learn in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (1.1.3)\n",
            "Requirement already satisfied: matplotlib in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (3.5.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from flwr[simulation]) (1.22.3)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from flwr[simulation]) (0.0.2)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.19.0 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from flwr[simulation]) (3.20.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.43.0 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from flwr[simulation]) (1.50.0)\n",
            "Collecting ray[default]<1.14.0,>=1.13.0\n",
            "  Downloading ray-1.13.0-cp310-cp310-manylinux2014_x86_64.whl (54.3 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from matplotlib) (9.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from matplotlib) (4.33.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from grpcio<2.0.0,>=1.43.0->flwr[simulation]) (1.16.0)\n",
            "Collecting aiosignal\n",
            "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (2.28.1)\n",
            "Requirement already satisfied: jsonschema in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (4.16.0)\n",
            "Collecting pyyaml\n",
            "  Using cached PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
            "Collecting grpcio<2.0.0,>=1.43.0\n",
            "  Downloading grpcio-1.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting virtualenv\n",
            "  Downloading virtualenv-20.16.6-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting click<=8.0.4,>=7.0\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist\n",
            "  Downloading frozenlist-1.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msgpack<2.0.0,>=1.0.0\n",
            "  Downloading msgpack-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m317.0/317.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (21.4.0)\n",
            "Collecting prometheus-client<0.14.0,>=0.7.1\n",
            "  Using cached prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
            "Collecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m90.5/90.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hCollecting colorful\n",
            "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m202.0/202.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting smart-open\n",
            "  Downloading smart_open-6.2.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m697.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting aiohttp>=3.7\n",
            "  Downloading aiohttp-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting opencensus\n",
            "  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (2.1.1)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting nvidia-ml-py<=11.495.46,>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from gpustat>=1.0.0b1->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (5.9.1)\n",
            "Collecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m784.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from jsonschema->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (0.18.1)\n",
            "Collecting google-api-core<3.0.0,>=1.0.0\n",
            "  Downloading google_api_core-2.10.2-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencensus-context>=0.1.3\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from requests->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from requests->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from requests->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (3.3)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from virtualenv->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (2.5.1)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /home/alex/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (0.2.5)\n",
            "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m211.7/211.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<3.0dev,>=1.25.0\n",
            "  Downloading google_auth-2.13.0-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Installing collected packages: pyasn1, py-spy, opencensus-context, nvidia-ml-py, msgpack, distlib, colorful, smart-open, rsa, pyyaml, pyasn1-modules, prometheus-client, multidict, grpcio, googleapis-common-protos, frozenlist, filelock, click, cachetools, blessed, async-timeout, yarl, virtualenv, gpustat, google-auth, aiosignal, ray, google-api-core, aiohttp, opencensus, aiohttp-cors\n",
            "  Attempting uninstall: prometheus-client\n",
            "    Found existing installation: prometheus-client 0.15.0\n",
            "    Uninstalling prometheus-client-0.15.0:\n",
            "      Successfully uninstalled prometheus-client-0.15.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.50.0\n",
            "    Uninstalling grpcio-1.50.0:\n",
            "      Successfully uninstalled grpcio-1.50.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.3\n",
            "    Uninstalling click-8.1.3:\n",
            "      Successfully uninstalled click-8.1.3\n",
            "\u001b[33m  DEPRECATION: gpustat is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py install for gpustat ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed aiohttp-3.8.3 aiohttp-cors-0.7.0 aiosignal-1.2.0 async-timeout-4.0.2 blessed-1.19.1 cachetools-5.2.0 click-8.0.4 colorful-0.5.4 distlib-0.3.6 filelock-3.8.0 frozenlist-1.3.1 google-api-core-2.10.2 google-auth-2.13.0 googleapis-common-protos-1.56.4 gpustat-1.0.0 grpcio-1.43.0 msgpack-1.0.4 multidict-6.0.2 nvidia-ml-py-11.495.46 opencensus-0.11.0 opencensus-context-0.1.3 prometheus-client-0.13.1 py-spy-0.3.14 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyyaml-6.0 ray-1.13.0 rsa-4.9 smart-open-6.2.0 virtualenv-20.16.6 yarl-1.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install flwr[simulation] scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UFT3_A3iz76"
      },
      "source": [
        "Now that we have the necessary packages installed, we can import everything we need for this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Tja2N6l-qH-e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flwr 1.0.0\n",
            "numpy 1.22.3\n",
            "sklearn 1.1.3\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from flwr.common import Metrics\n",
        "\n",
        "print(\"flwr\", fl.__version__)\n",
        "print(\"numpy\", np.__version__)\n",
        "print(\"sklearn\", sklearn.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcgAAiaihnx"
      },
      "source": [
        "### Loading the data\n",
        "\n",
        "In this tutorial, we'll introduce federated learning by training a simple neural\n",
        "network on the MNIST handwritten digit recognition dataset, a well-known\n",
        "computer vision benchmark. The task is to recognize images of the digits 0-9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toxAoOq6fS2h"
      },
      "source": [
        "We simulate having multiple users by splitting the dataset into partitions. Each\n",
        "partition will represent the data from a single user. We're doing this purely\n",
        "for experimentation purposes, in the real world there's no need for data\n",
        "splitting because each user already has their own data local to their device.\n",
        "Each user's device is a client, so having ten clients participate in a\n",
        "federation means having ten clients connected to the federated learning server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9LhPFDh0S5c"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Zy7yjBPhQd"
      },
      "source": [
        "\n",
        "Let's now load the MNIST training and test set, partition them into ten smaller datasets (each split into training and validation set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(num_clients: int):\n",
        "    \"\"\"Get a subset of the training data for one client.\"\"\"\n",
        "    X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
        "    X_splits = np.split(X, num_clients)\n",
        "    y_splits = np.split(y, num_clients)\n",
        "    return [train_test_split(Xs, ys, random_state=0, test_size=0.2) for Xs, ys in zip(X_splits, y_splits)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'num_clients' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/alex/federated-learning-starter/flower_tutorial.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alex/federated-learning-starter/flower_tutorial.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m X, y \u001b[39m=\u001b[39m fetch_openml(\u001b[39m\"\u001b[39m\u001b[39mmnist_784\u001b[39m\u001b[39m\"\u001b[39m, version\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, return_X_y\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, as_frame\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alex/federated-learning-starter/flower_tutorial.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m X_splits \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msplit(X, num_clients)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alex/federated-learning-starter/flower_tutorial.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m y_splits \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msplit(y, num_clients)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_clients' is not defined"
          ]
        }
      ],
      "source": [
        "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "num_clients=10\n",
        "X_splits = np.split(X, num_clients)\n",
        "y_splits = np.split(y, num_clients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]])]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3dag9WeT9VH"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
        "    plt.show()\n",
        "# TODO: call on an example image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TW4Pzb7p1F9"
      },
      "source": [
        "## Part 1: Centralized Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTjCmmBtqPgM"
      },
      "source": [
        "Next, we're going to define a simple model and train it locally.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYks8IpJL6iK"
      },
      "source": [
        "### Defining the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2X3cVBXMpP6w"
      },
      "outputs": [],
      "source": [
        "model = MLPClassifier(\n",
        "    solver=\"adam\",\n",
        "    alpha=1e-5,\n",
        "    hidden_layer_sizes=(5, 2),\n",
        "    batch_size=32,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDDxh73Sszck"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "We now have all the basic building blocks we need: a dataset, a model, a training function, and a test function. Let's put them together to train the model on the dataset of one of our organizations (`trainloaders[0]`). This simulates the reality of most machine learning projects today: each organization has their own data and trains models only on this internal data: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdUTb8WgtRMz"
      },
      "outputs": [],
      "source": [
        "trainloader = trainloaders[0]\n",
        "valloader = valloaders[0]\n",
        "net = Net().to(DEVICE)\n",
        "\n",
        "for epoch in range(5):\n",
        "    train(net, trainloader, 1)\n",
        "    loss, accuracy = test(net, valloader)\n",
        "    print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
        "\n",
        "loss, accuracy = test(net, testloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhLGLdmhOhVr"
      },
      "source": [
        "Training the simple CNN on our CIFAR-10 split for 5 epochs should result in a test set accuracy of about 41%, which is not good, but at the same time, it doesn't really matter for the purposes of this tutorial. The intent was just to show a simplistic centralized training pipeline that sets the stage for what comes next - federated learning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6HP2cYCsqxD"
      },
      "source": [
        "## Part 2: Federated Learning with Flower\n",
        "\n",
        "Part 1 demonstrated a simple centralized training pipeline. All data was in one place (i.e., a single `trainloader` and a single `valloader`). Next, we'll simulate a situation where we have multiple datasets in multiple organizations and where we train a model over these organizations using federated learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf-cW093MzeT"
      },
      "source": [
        "### Updating model parameters\n",
        "\n",
        "In federated learning, the server sends the global model parameters to the client, and the client updates the local model with the parameters received from the server. It then trains the model on the local data (which changes the model parameters locally) and sends the updated/changed model parameters back to the server (or, alternatively, it sends just the gradients back to the server, not the full model parameters).\n",
        "\n",
        "We need two helper functions to update the local model with parameters received from the server and to get the updated model parameters from the local model: `set_parameters` and `get_parameters`. The following two functions do just that for the PyTorch model above.\n",
        "\n",
        "The details of how this works are not really important here (feel free to consult the PyTorch documentation if you want to learn more). In essence, we use `state_dict` to access PyTorch model parameter tensors. The parameter tensors are then converted to/from a list of NumPy ndarray's (which Flower knows how to serialize/deserialize):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZxGk6AMNvvV"
      },
      "outputs": [],
      "source": [
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lCf3oljdClM"
      },
      "source": [
        "### Implementing a Flower client\n",
        "\n",
        "With that out of the way, let's move on to the interesting part. Federated learning systems consist of a server and multiple clients. In Flower, we create clients by implementing subclasses of `flwr.client.Client` or `flwr.client.NumPyClient`. We use `NumPyClient` in this tutorial because it is easier to implement and requires us to write less boilerplate.\n",
        "\n",
        "To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`:\n",
        "\n",
        "* `get_parameters`: Return the current local model parameters\n",
        "* `fit`: Receive model parameters from the server, train the model parameters on the local data, and return the (updated) model parameters to the server\n",
        "* `evaluate`: Receive model parameters from the server, evaluate the model parameters on the local data, and return the evaluation result to the server\n",
        "\n",
        "We mentioned that our clients will use the previously defined PyTorch components for model training and evaluation. Let's see a simple Flower client implementation that brings everything together:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye6Jt5p3LWtF"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Heyxd9MfHOTe"
      },
      "source": [
        "Our class `FlowerClient` defines how local training/evaluation will be performed and allows Flower to call the local training/evaluation through `fit` and `evaluate`. Each instance of `FlowerClient` represents a *single client* in our federated learning system. Federated learning systems have multiple clients (otherwise there's not much to federate), so each client will be represented by its own instance of `FlowerClient`. If we have, for example, three clients in our workload, then we'd have three instances of `FlowerClient`. Flower calls `FlowerClient.fit` on the respective instance when the server selects a particular client for training (and `FlowerClient.evaluate` for evaluation).\n",
        "\n",
        "### Using the Virtual Client Engine\n",
        "\n",
        "In this notebook, we want to simulate a federated learning system with 10 clients on a single machine. This means that the server and all 10 clients will live on a single machine and share resources such as CPU, GPU, and memory. Having 10 clients would mean having 10 instances of `FlowerClient` im memory. Doing this on a single machine can quickly exhaust the available memory resources, even if only a subset of these clients participates in a single round of federated learning.\n",
        "\n",
        "In addition to the regular capabilities where server and clients run on multiple machines, Flower therefore provides special simulation capabilities that create `FlowerClient` instances only when they are actually necessary for training or evaluation. To enable the Flower framework to create clients when necessary, we need to implement a function called `client_fn` that creates a `FlowerClient` instance on demand. Flower calls `client_fn` whenever it needs an instance of one particular client to call `fit` or `evaluate` (those instances are usually discarded after use, so they should not keep any local state). Clients are identified by a client ID, or short `cid`. The `cid` can be used, for example, to load different local data partitions for different clients, as can be seen below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkcwggRYOwWN"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    net = Net().to(DEVICE)\n",
        "\n",
        "    # Load data (CIFAR-10)\n",
        "    # Note: each client gets a different trainloader/valloader, so each client\n",
        "    # will train and evaluate on their own unique data\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "\n",
        "    # Create a  single Flower client representing a single organization\n",
        "    return FlowerClient(net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axzXSMtlfhXU"
      },
      "source": [
        "### Starting the training\n",
        "\n",
        "We now have the class `FlowerClient` which defines client-side training/evaluation and `client_fn` which allows Flower to create `FlowerClient` instances whenever it needs to call `fit` or `evaluate` on one particular client. The last step is to start the actual simulation using `flwr.simulation.start_simulation`. \n",
        "\n",
        "The function `start_simulation` accepts a number of arguments, amongst them the `client_fn` used to create `FlowerClient` instances, the number of clients to simulate (`num_clients`), the number of federated learning rounds (`num_rounds`), and the strategy. The strategy encapsulates the federated learning approach/algorithm, for example, *Federated Averaging* (FedAvg).\n",
        "\n",
        "Flower has a number of built-in strategies, but we can also use our own strategy implementations to customize nearly all aspects of the federated learning approach. For this example, we use the built-in `FedAvg` implementation and customize it using a few basic parameters. The last step is the actual call to `start_simulation` which - you guessed it - starts the simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELNy0-0nfyI2"
      },
      "outputs": [],
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
        "        min_fit_clients=10,  # Never sample less than 10 clients for training\n",
        "        min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "        min_available_clients=10,  # Wait until all 10 clients are available\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_lIXlErb9qN"
      },
      "source": [
        "### Behind the scenes\n",
        "\n",
        "So how does this work? How does Flower execute this simulation?\n",
        "\n",
        "When we call `start_simulation`, we tell Flower that there are 10 clients (`num_clients=10`). Flower then goes ahead an asks the `FedAvg` strategy to select clients. `FedAvg` knows that it should select 100% of the available clients (`fraction_fit=1.0`), so it goes ahead and selects 10 random clients (i.e., 100% of 10).\n",
        "\n",
        "Flower then asks the selected 10 clients to train the model. When the server receives the model parameter updates from the clients, it hands those updates over to the strategy (*FedAvg*) for aggregation. The strategy aggregates those updates and returns the new global model, which then gets used in the next round of federated learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Where's the accuracy?\n",
        "\n",
        "You may have noticed that all metrics except for `losses_distributed` are empty. Where did the `{\"accuracy\": float(accuracy)}` go?\n",
        "\n",
        "Flower can automatically aggregate losses returned by individual clients, but it cannot do the same for metrics in the generic metrics dictionary (the one with the `accuracy` key). Metrics dictionaries can contain very different kinds of metrics and even key/value pairs that are not metrics at all, so the framework does not (and can not) know how to handle these automatically.\n",
        "\n",
        "As users, we need to tell the framework how to handle/aggregate these custom metrics, and we do so by passing metric aggregation functions to the strategy. The strategy will then call these functions whenever it receives fit or evaluate metrics from clients. The two possible functions are `fit_metrics_aggregation_fn` and `evaluate_metrics_aggregation_fn`.\n",
        "\n",
        "Let's create a simple weighted averaging function to aggregate the `accuracy` metric we return from `evaluate`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "    \n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The only thing left to do is to tell the strategy to call this function whenever it receives evaluation metric dictionaries from the clients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=0.5,\n",
        "        min_fit_clients=10,\n",
        "        min_evaluate_clients=5,\n",
        "        min_available_clients=10,\n",
        "        evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now have a full system that performs federated training and federated evaluation. It uses the `weighted_average` function to aggregate custom evaluation metrics and calculates a single `accuracy` metric across all clients on the server side.\n",
        "\n",
        "The other two categories of metrics (`losses_centralized` and `metrics_centralized`) are still empty because they only apply when centralized evaluation is being used. Part two of the Flower tutorial will cover centralized evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umvwX56Of3Cr"
      },
      "source": [
        "## Final remarks\n",
        "\n",
        "Congratulations, you just trained a convolutional neural network, federated over 10 clients! With that, you understand the basics of federated learning with Flower. The same approach you've seen can be used with other machine learning frameworks (not just PyTorch) and tasks (not just CIFAR-10 images classification), for example NLP with Hugging Face Transformers or speech with SpeechBrain.\n",
        "\n",
        "In the next notebook, we're going to cover some more advanced concepts. Want to customize your strategy? Initialize parameters on the server side? Or evaluate the aggregated model on the server side? We'll cover all this and more in the next tutorial."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Flower-1-Intro-to-FL-PyTorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit ('3.10.2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "e91b11cb70a8a54f4dc4cfa7d068ead2808e7bd6238931b69a30c8c1a41601f9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
