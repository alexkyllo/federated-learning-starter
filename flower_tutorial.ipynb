{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz71fPGrpRiQ"
      },
      "source": [
        "# Intro to Federated Learning with Flower and Keras\n",
        "\n",
        "Alex Kyllo 2022-10-29\n",
        "\n",
        "Adapted from:\n",
        "[An Introduction to Federated Learning (flower.dev)](https://flower.dev/docs/tutorial/Flower-1-Intro-to-FL-PyTorch.html)\n",
        "\n",
        "In this notebook, we'll build a simulated federated learning system using Flower\n",
        "and Keras.\n",
        "\n",
        "In a production FL environment, you would have a central server communicating\n",
        "with many clients on different machines (like smartphones) over the network, but\n",
        "Flower provides a simulation framework so that you can run a whole FL environment\n",
        "locally, even in a Jupyter notebook like this.\n",
        "\n",
        "Let's get started! ðŸŒ»"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBu1HRRY6bwX"
      },
      "source": [
        "## Step 0: Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4KiTMTpiort"
      },
      "source": [
        "### Installing dependencies\n",
        "\n",
        "First, let's install Python packages we need to run the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTrCL2FmC5U5"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] tensorflow numpy matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UFT3_A3iz76"
      },
      "source": [
        "Now that we have the necessary packages installed, we can import everything we need for this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tja2N6l-qH-e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "# Silence TF warnings\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import flwr as fl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from flwr.common import Metrics\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.simulation import start_simulation\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(\"flwr\", fl.__version__)\n",
        "print(\"numpy\", np.__version__)\n",
        "print(\"tensorflow\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcgAAiaihnx"
      },
      "source": [
        "### Loading the data\n",
        "\n",
        "In this tutorial, we'll introduce federated learning by training a simple neural\n",
        "network on the MNIST handwritten digit recognition dataset, a well-known\n",
        "computer vision benchmark. The task is to recognize images of the digits 0-9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toxAoOq6fS2h"
      },
      "source": [
        "We simulate having multiple users by splitting the dataset into partitions. Each\n",
        "partition will represent the data from a single user. We're doing this purely\n",
        "for experimentation purposes, in the real world there's no need for data\n",
        "splitting because each user already has their own data local to their device.\n",
        "Each user's device is a client, so having ten clients participate in a\n",
        "federation means having ten clients connected to the federated learning server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9LhPFDh0S5c"
      },
      "outputs": [],
      "source": [
        "# Set some config variables\n",
        "NUM_CLIENTS = 10\n",
        "NUM_CLASSES = 10\n",
        "NUM_ROUNDS = 3\n",
        "INPUT_SHAPE = (28, 28, 1)\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Zy7yjBPhQd"
      },
      "source": [
        "Let's load the MNIST training and test set and partition them into ten smaller datasets (each split into training and validation set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train.astype(np.float32) / 255\n",
        "x_test = x_test.astype(np.float32) / 255\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "y_train_onehot = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test_onehot = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
        "# split data for clients\n",
        "x_train_splits = np.array_split(x_train, NUM_CLIENTS)\n",
        "y_train_splits = np.array_split(y_train_onehot, NUM_CLIENTS)\n",
        "x_test_splits = np.array_split(x_test, NUM_CLIENTS)\n",
        "y_test_splits = np.array_split(y_test_onehot, NUM_CLIENTS)\n",
        "data_splits = [((x, y), (xt, yt)) for (x, y, xt, yt) in zip(x_train_splits, y_train_splits, x_test_splits, y_test_splits)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then let's plot a sample of the MNIST digits just to visualize the data we're\n",
        "using for the ML task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2,5)\n",
        "for i, ax in enumerate(ax.flatten()):\n",
        "    im_idx = np.argwhere(y_train == i)[0,0]\n",
        "    plottable_image = np.reshape(x_train[im_idx], (28, 28))\n",
        "    ax.imshow(plottable_image, cmap='gray_r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TW4Pzb7p1F9"
      },
      "source": [
        "## Step 1: Design and train your model in a centralized setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTjCmmBtqPgM"
      },
      "source": [
        "Before moving into federated learning, it's best to develop your model with a\n",
        "data sample in a centralized setting so that you can debug any issues with the\n",
        "model itself and have a baseline to compare your FL model's performance against.\n",
        "\n",
        "Here, since we already split the data into tenths for the ten clients, we'll\n",
        "train the model on just one of the client splits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYks8IpJL6iK"
      },
      "source": [
        "### Defining the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X3cVBXMpP6w"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=INPUT_SHAPE),\n",
        "            # Comment out the two Dense layers\n",
        "            # and uncomment the Conv2D and MaxPooling layers layers if you want a CNN\n",
        "            layers.Dense(8, activation=\"relu\"),\n",
        "            layers.Dense(4, activation=\"relu\"),\n",
        "            # layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "            # layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            # layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "            # layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            layers.Flatten(),\n",
        "            # layers.Dropout(0.5),\n",
        "            layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0005), metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(x_train_0, y_train_0), (x_test_0, y_test_0) = data_splits[0]\n",
        "model.fit(x_train_0, y_train_0, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhLGLdmhOhVr"
      },
      "source": [
        "Here we demonstrated a simple centralized training pipeline. Next, we'll\n",
        "simulate a situation where we have multiple datasets across multiple devices and\n",
        "where we train the same model over these devices using federated learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lCf3oljdClM"
      },
      "source": [
        "## Step 2: Implement a Flower client\n",
        "\n",
        "Federated learning systems consist of a server and multiple clients. In Flower, we create clients by implementing subclasses of `flwr.client.Client` or `flwr.client.NumPyClient`. We use `NumPyClient` in this tutorial because it is easier to implement and requires us to write less boilerplate.\n",
        "\n",
        "To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`:\n",
        "\n",
        "* `get_parameters`: Return the current local model parameters\n",
        "* `fit`: Receive model parameters from the server, train the model parameters on the local data, and return the (updated) model parameters to the server\n",
        "* `evaluate`: Receive model parameters from the server, evaluate the model parameters on the local data, and return the evaluation result to the server\n",
        "\n",
        "Let's see a simple Flower client implementation that brings everything together:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye6Jt5p3LWtF"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, cid, train_data, test_data, epochs, batch_size):\n",
        "        self.model = model\n",
        "        self.cid = int(cid)\n",
        "        self.x_train, self.y_train = train_data\n",
        "        self.x_test, self.y_test = test_data\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return self.model.get_weights()\n",
        "    \n",
        "    def fit(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size)\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, accuracy = self.model.evaluate(self.x_test, self.y_test)\n",
        "        return loss, len(self.x_test), {\"accuracy\": float(accuracy)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Heyxd9MfHOTe"
      },
      "source": [
        "Our class `FlowerClient` defines how local training/evaluation will be performed and allows Flower to call the local training/evaluation through `fit` and `evaluate`. Each instance of `FlowerClient` represents a *single client* in our federated learning system. Federated learning systems have multiple clients (otherwise there's not much to federate), so each client will be represented by its own instance of `FlowerClient`. If we have, for example, three clients in our workload, then we'd have three instances of `FlowerClient`. Flower calls `FlowerClient.fit` on the respective instance when the server selects a particular client for training (and `FlowerClient.evaluate` for evaluation).\n",
        "\n",
        "### Using the Virtual Client Engine\n",
        "\n",
        "In this notebook, we want to simulate a federated learning system with 10 clients on a single machine. This means that the server and all 10 clients will live on a single machine and share resources such as CPU, GPU, and memory. Having 10 clients would mean having 10 instances of `FlowerClient` im memory. Doing this on a single machine can quickly exhaust the available memory resources, even if only a subset of these clients participates in a single round of federated learning.\n",
        "\n",
        "In addition to the regular capabilities where server and clients run on multiple machines, Flower therefore provides special simulation capabilities that create `FlowerClient` instances only when they are actually necessary for training or evaluation. To enable the Flower framework to create clients when necessary, we need to implement a function called `client_fn` that creates a `FlowerClient` instance on demand. Flower calls `client_fn` whenever it needs an instance of one particular client to call `fit` or `evaluate` (those instances are usually discarded after use, so they should not keep any local state). Clients are identified by a client ID, or short `cid`. The `cid` can be used, for example, to load different local data partitions for different clients, as can be seen below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkcwggRYOwWN"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "    print(f\"cid: {cid}\")\n",
        "    # Load data (MNIST) and\n",
        "    (x_train, y_train), (x_test, y_test) = data_splits[int(cid)]\n",
        "    # Create a single Flower client representing a single device\n",
        "    return FlowerClient(build_model(), cid, (x_train, y_train), (x_test, y_test), epochs=EPOCHS, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Select and configure a strategy\n",
        "\n",
        "### Updating model parameters\n",
        "\n",
        "In federated learning, the server sends the global model parameters (or\n",
        "alternatively, gradients) to the client, and the client updates the local model\n",
        "with the parameters received from the server. It then trains the model on the\n",
        "local data, which changes the model parameters locally, and sends the updated\n",
        "model parameters back to the server. The server averages the parameter updates\n",
        "from the multiple clients together to update the global model. This is called a\n",
        "\"round\" and the number of rounds to train for is a hyperparameter in FL, in\n",
        "addition to the number of local training epochs each client should conduct\n",
        "within one round.\n",
        "\n",
        "There are multiple ways the server can aggregate parameter updates from the\n",
        "clients--these algorithms are called \"strategies\" in Flower, which uses the\n",
        "Strategy Pattern to manage them. There are many strategies available, the\n",
        "simplest of which is `FedAvg`, which is just a weighted average of the\n",
        "parameters, weighted by the number of training samples each client has. We'll\n",
        "start with this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aggregate metrics\n",
        "\n",
        "In order to evaluate the performance of our model, we need a metric. Flower can\n",
        "automatically aggregate losses returned by individual clients, but it cannot do\n",
        "the same for metrics in the generic metrics dictionary (the one with the\n",
        "`accuracy` key). Metrics dictionaries can contain very different kinds of\n",
        "metrics and even key/value pairs that are not metrics at all, so the framework\n",
        "does not (and can not) know how to handle these automatically.\n",
        "\n",
        "As users, we need to tell the framework how to handle/aggregate these custom\n",
        "metrics, and we do so by passing metric aggregation functions to the strategy.\n",
        "The strategy will then call these functions whenever it receives fit or evaluate\n",
        "metrics from clients. The two possible functions are\n",
        "`fit_metrics_aggregation_fn` and `evaluate_metrics_aggregation_fn`.\n",
        "\n",
        "Let's create a simple weighted averaging function to aggregate the `accuracy`\n",
        "metric we return from `evaluate`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "    \n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then let's create our `FedAvg` strategy and provide the `weighted_average`\n",
        "metric to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = FedAvg(\n",
        "        fraction_fit=1.0,                                 # Proportion of clients to sample in each training round\n",
        "        fraction_evaluate=0.5,                            # Proportion of clients to calculate accuracy on after each round\n",
        "        min_fit_clients=10,                               # Minimum number of clients to train on in each round\n",
        "        min_evaluate_clients=5,                           # Minimum number of clients to evaluate accuracy on after each round\n",
        "        min_available_clients=10,                         # Minimum number of available clients needed to start a round\n",
        "        evaluate_metrics_aggregation_fn=weighted_average, # <-- pass the metric aggregation function\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axzXSMtlfhXU"
      },
      "source": [
        "## Step 4: Run the federated training simulation\n",
        "\n",
        "We now have the class `FlowerClient` which defines client-side training/evaluation and `client_fn` which allows Flower to create `FlowerClient` instances whenever it needs to call `fit` or `evaluate` on one particular client. The last step is to start the actual simulation using `flwr.simulation.start_simulation`. \n",
        "\n",
        "The function `start_simulation` accepts a number of arguments, amongst them the `client_fn` used to create `FlowerClient` instances, the number of clients to simulate (`num_clients`), the number of federated learning rounds (`num_rounds`), and the strategy we just configured.\n",
        "\n",
        "The last step is the actual call to `start_simulation` which - you guessed it - starts the simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start simulation\n",
        "history = start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_lIXlErb9qN"
      },
      "source": [
        "### Behind the scenes\n",
        "\n",
        "So how does this work? How does Flower execute this simulation?\n",
        "\n",
        "When we call `start_simulation`, we tell Flower that there are 10 clients (`num_clients=10`). Flower then goes ahead an asks the `FedAvg` strategy to select clients. `FedAvg` knows that it should select 100% of the available clients (`fraction_fit=1.0`), so it goes ahead and selects 10 random clients (i.e., 100% of 10).\n",
        "\n",
        "Flower then asks the selected 10 clients to train the model. When the server receives the model parameter updates from the clients, it hands those updates over to the strategy (*FedAvg*) for aggregation. The strategy aggregates those updates and returns the new global model, which then gets used in the next round of federated learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now have a full system that performs federated training and federated evaluation. It uses the `weighted_average` function to aggregate custom evaluation metrics and calculates a single `accuracy` metric across all clients on the server side.\n",
        "\n",
        "The other two categories of metrics (`losses_centralized` and `metrics_centralized`) are still empty because they only apply when centralized evaluation is being used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umvwX56Of3Cr"
      },
      "source": [
        "## Beyond\n",
        "\n",
        "Congratulations, you just trained a neural network, federated over 10 clients!\n",
        "With that, you understand the basics of federated learning with Flower. The same\n",
        "approach you've seen can be used with other machine learning frameworks like\n",
        "PyTorch or TensorFlow. If you've gotten this far and your model works well in\n",
        "simulation, you can use more features of Flower to adapt it to run for real on\n",
        "distributed client devices, including\n",
        "[Android smartphones](https://flower.dev/blog/2021-12-15-federated-learning-on-android-devices-with-flower/)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Flower-1-Intro-to-FL-PyTorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "6180f38cd67bbe86689803677925c16b139de4101779652254d1c72c55163899"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
